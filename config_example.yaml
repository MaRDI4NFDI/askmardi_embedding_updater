# Run parameters
run_params:
  update_embeddings_loop_iterations: 1
  update_embeddings_embeddings_per_loop: 10

# LakeFS settings
lakefs:
  url: "https://lake-bioinfmed.zib.de/"
  state_repo: "mardi-workflows-files"
  state_repo_directory: "askmardi_embedding_update"
  data_repo: "mardi-fdo-data"
  branch: "main"
  user: 'MYUSER'
  password: 'MYPASSWORD'

# MaRDI KG settings
mardi_kg:
  sparql_endpoint: "https://query.portal.mardi4nfdi.de/sparql"
  mardi_software_profile_qid: "Q5976450"             # Instance of software in Wikibase
  mardi_profile_type_pid: "P1460"

# DOIP server
doip:
  endpoint: "https://doip.portal.mardi4nfdi.de/doip"
  timeout_seconds: 30

# Qdrant storage
qdrant:
  url: "http://localhost:6333"
  collection: "software_docs"
  vector_size: 768                 # example dimension
  distance: "Cosine"
  api_key: ""                      # if required

# Embedding Model
embedding:
  model_name: "sentence-transformers/all-MiniLM-L6-v2"
  batch_size: 4
  device: "cpu"                    # "cuda" if GPU available

llm:
  # Base URL for an OpenAI-compatible endpoint
  host: "https://ollama.zib.de/api"
  model_name: "gemma3:27b"
  api_key: "MYKEY"

# SPARQL workflow settings
sparql:
  sleep_between_queries: 10
  sparql_max_results: 10
  sparql_max_results_per_query: 5
  max_retries: 5
  timeout: 600
